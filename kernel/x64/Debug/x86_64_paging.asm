; Listing generated by Microsoft (R) Optimizing Compiler Version 18.00.21005.1 

include listing.inc

INCLUDELIB LIBCMT
INCLUDELIB OLDNAMES

PUBLIC	?x86_64_paging_init@@YAHXZ			; x86_64_paging_init
PUBLIC	?early_map_page@@YA_N_K0E@Z			; early_map_page
PUBLIC	?x86_64_phys_to_virt@@YA_K_K@Z			; x86_64_phys_to_virt
PUBLIC	?x86_64_virt_to_phys@@YA_K_K@Z			; x86_64_virt_to_phys
PUBLIC	?x86_64_map_page@@YA_N_K0E@Z			; x86_64_map_page
EXTRN	?x86_64_pmmngr_alloc@@YAPEAXXZ:PROC		; x86_64_pmmngr_alloc
EXTRN	?x86_64_pmmngr_free@@YAXPEAX@Z:PROC		; x86_64_pmmngr_free
EXTRN	?x86_64_pmmngr_get_total_mem@@YA_KXZ:PROC	; x86_64_pmmngr_get_total_mem
EXTRN	?x86_64_pmmngr_set_high@@YAX_N@Z:PROC		; x86_64_pmmngr_set_high
EXTRN	?x86_64_pmmngr_is_high_mem@@YA_NXZ:PROC		; x86_64_pmmngr_is_high_mem
EXTRN	?x86_64_pmmngr_high_mem_bitmap@@YAXXZ:PROC	; x86_64_pmmngr_high_mem_bitmap
EXTRN	x64_mfence:PROC
EXTRN	x64_read_cr3:PROC
EXTRN	x64_write_cr3:PROC
EXTRN	flush_tlb:PROC
EXTRN	?memset@@YAXPEAXEI@Z:PROC			; memset
pdata	SEGMENT
$pdata$?x86_64_paging_init@@YAHXZ DD imagerel $LN15
	DD	imagerel $LN15+326
	DD	imagerel $unwind$?x86_64_paging_init@@YAHXZ
$pdata$?early_map_page@@YA_N_K0E@Z DD imagerel $LN6
	DD	imagerel $LN6+562
	DD	imagerel $unwind$?early_map_page@@YA_N_K0E@Z
$pdata$?x86_64_phys_to_virt@@YA_K_K@Z DD imagerel $LN5
	DD	imagerel $LN5+56
	DD	imagerel $unwind$?x86_64_phys_to_virt@@YA_K_K@Z
$pdata$?x86_64_virt_to_phys@@YA_K_K@Z DD imagerel $LN5
	DD	imagerel $LN5+53
	DD	imagerel $unwind$?x86_64_virt_to_phys@@YA_K_K@Z
$pdata$?x86_64_map_page@@YA_N_K0E@Z DD imagerel $LN8
	DD	imagerel $LN8+626
	DD	imagerel $unwind$?x86_64_map_page@@YA_N_K0E@Z
pdata	ENDS
xdata	SEGMENT
$unwind$?x86_64_paging_init@@YAHXZ DD 010401H
	DD	08204H
$unwind$?early_map_page@@YA_N_K0E@Z DD 021601H
	DD	0110116H
$unwind$?x86_64_phys_to_virt@@YA_K_K@Z DD 010901H
	DD	04209H
$unwind$?x86_64_virt_to_phys@@YA_K_K@Z DD 010901H
	DD	04209H
$unwind$?x86_64_map_page@@YA_N_K0E@Z DD 011301H
	DD	0e213H
xdata	ENDS
; Function compile flags: /Odtpy
; File e:\aurora kernel\kernel\arch\x86_64\x86_64_paging.cpp
_TEXT	SEGMENT
i2$ = 32
i4$ = 36
i3$ = 40
i1$ = 44
flags$ = 48
pml4i$ = 56
pml3$ = 64
pml2$ = 72
page$1 = 80
page$2 = 88
page$3 = 96
pml1$ = 104
phys$ = 128
virt$ = 136
attrib$ = 144
?x86_64_map_page@@YA_N_K0E@Z PROC			; x86_64_map_page

; 157  : bool x86_64_map_page(uint64_t phys, uint64_t virt, uint8_t attrib) {

$LN8:
	mov	BYTE PTR [rsp+24], r8b
	mov	QWORD PTR [rsp+16], rdx
	mov	QWORD PTR [rsp+8], rcx
	sub	rsp, 120				; 00000078H

; 158  : 
; 159  : 	if (!x86_64_pmmngr_is_high_mem())

	call	?x86_64_pmmngr_is_high_mem@@YA_NXZ	; x86_64_pmmngr_is_high_mem
	movzx	eax, al
	test	eax, eax
	jne	SHORT $LN5@x86_64_map

; 160  : 		return early_map_page(phys, virt, attrib);

	movzx	r8d, BYTE PTR attrib$[rsp]
	mov	rdx, QWORD PTR virt$[rsp]
	mov	rcx, QWORD PTR phys$[rsp]
	call	?early_map_page@@YA_N_K0E@Z		; early_map_page
	jmp	$LN6@x86_64_map
$LN5@x86_64_map:

; 161  : 
; 162  : 	size_t flags = PAGING_PRESENT | PAGING_WRITABLE | attrib;

	movzx	eax, BYTE PTR attrib$[rsp]
	or	eax, 3
	cdqe
	mov	QWORD PTR flags$[rsp], rax

; 163  : 
; 164  : 	const long i4 = (virt >> 39) & 0x1FF;

	mov	rax, QWORD PTR virt$[rsp]
	shr	rax, 39					; 00000027H
	and	rax, 511				; 000001ffH
	mov	DWORD PTR i4$[rsp], eax

; 165  : 	const long i3 = (virt >> 30) & 0x1FF;

	mov	rax, QWORD PTR virt$[rsp]
	shr	rax, 30
	and	rax, 511				; 000001ffH
	mov	DWORD PTR i3$[rsp], eax

; 166  : 	const long i2 = (virt >> 21) & 0x1FF;

	mov	rax, QWORD PTR virt$[rsp]
	shr	rax, 21
	and	rax, 511				; 000001ffH
	mov	DWORD PTR i2$[rsp], eax

; 167  : 	const long i1 = (virt >> 12) & 0x1FF;

	mov	rax, QWORD PTR virt$[rsp]
	shr	rax, 12
	and	rax, 511				; 000001ffH
	mov	DWORD PTR i1$[rsp], eax

; 168  : 
; 169  : 	uint64_t *pml4i = (uint64_t*)x86_64_phys_to_virt(x64_read_cr3());

	call	x64_read_cr3
	mov	rcx, rax
	call	?x86_64_phys_to_virt@@YA_K_K@Z		; x86_64_phys_to_virt
	mov	QWORD PTR pml4i$[rsp], rax

; 170  : 	if (!(x86_64_phys_to_virt(pml4i[i4]) & PAGING_PRESENT)) {

	movsxd	rax, DWORD PTR i4$[rsp]
	mov	rcx, QWORD PTR pml4i$[rsp]
	mov	rcx, QWORD PTR [rcx+rax*8]
	call	?x86_64_phys_to_virt@@YA_K_K@Z		; x86_64_phys_to_virt
	and	rax, 1
	test	rax, rax
	jne	SHORT $LN4@x86_64_map

; 171  : 		uint64_t page = (uint64_t)x86_64_pmmngr_alloc();

	call	?x86_64_pmmngr_alloc@@YAPEAXXZ		; x86_64_pmmngr_alloc
	mov	QWORD PTR page$1[rsp], rax

; 172  : 		pml4i[i4] = page | flags;

	mov	rax, QWORD PTR flags$[rsp]
	mov	rcx, QWORD PTR page$1[rsp]
	or	rcx, rax
	mov	rax, rcx
	movsxd	rcx, DWORD PTR i4$[rsp]
	mov	rdx, QWORD PTR pml4i$[rsp]
	mov	QWORD PTR [rdx+rcx*8], rax

; 173  : 		flush_tlb((void*)page);

	mov	rcx, QWORD PTR page$1[rsp]
	call	flush_tlb

; 174  : 		x64_mfence();

	call	x64_mfence
$LN4@x86_64_map:

; 175  : 	}
; 176  : 
; 177  : 	uint64_t* pml3 = (uint64_t*)x86_64_phys_to_virt(pml4i[i4] & ~(4096 - 1));

	movsxd	rax, DWORD PTR i4$[rsp]
	mov	rcx, QWORD PTR pml4i$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, -4096				; fffffffffffff000H
	mov	rcx, rax
	call	?x86_64_phys_to_virt@@YA_K_K@Z		; x86_64_phys_to_virt
	mov	QWORD PTR pml3$[rsp], rax

; 178  : 	if (!(pml3[i3] & PAGING_PRESENT)) {

	movsxd	rax, DWORD PTR i3$[rsp]
	mov	rcx, QWORD PTR pml3$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, 1
	test	rax, rax
	jne	SHORT $LN3@x86_64_map

; 179  : 		const uint64_t page = (uint64_t)x86_64_pmmngr_alloc();

	call	?x86_64_pmmngr_alloc@@YAPEAXXZ		; x86_64_pmmngr_alloc
	mov	QWORD PTR page$3[rsp], rax

; 180  : 		pml3[i3] = page | flags;

	mov	rax, QWORD PTR flags$[rsp]
	mov	rcx, QWORD PTR page$3[rsp]
	or	rcx, rax
	mov	rax, rcx
	movsxd	rcx, DWORD PTR i3$[rsp]
	mov	rdx, QWORD PTR pml3$[rsp]
	mov	QWORD PTR [rdx+rcx*8], rax

; 181  : 		flush_tlb((void*)page);

	mov	rcx, QWORD PTR page$3[rsp]
	call	flush_tlb

; 182  : 		x64_mfence();

	call	x64_mfence
$LN3@x86_64_map:

; 183  : 	}
; 184  : 
; 185  : 	uint64_t* pml2 = (uint64_t*)x86_64_phys_to_virt((pml3[i3] & ~(4096 - 1)));

	movsxd	rax, DWORD PTR i3$[rsp]
	mov	rcx, QWORD PTR pml3$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, -4096				; fffffffffffff000H
	mov	rcx, rax
	call	?x86_64_phys_to_virt@@YA_K_K@Z		; x86_64_phys_to_virt
	mov	QWORD PTR pml2$[rsp], rax

; 186  : 
; 187  : 	if (!(pml2[i2] & PAGING_PRESENT)) {

	movsxd	rax, DWORD PTR i2$[rsp]
	mov	rcx, QWORD PTR pml2$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, 1
	test	rax, rax
	jne	SHORT $LN2@x86_64_map

; 188  : 		const uint64_t page = (uint64_t)x86_64_pmmngr_alloc();

	call	?x86_64_pmmngr_alloc@@YAPEAXXZ		; x86_64_pmmngr_alloc
	mov	QWORD PTR page$2[rsp], rax

; 189  : 		pml2[i2] = page | flags;

	mov	rax, QWORD PTR flags$[rsp]
	mov	rcx, QWORD PTR page$2[rsp]
	or	rcx, rax
	mov	rax, rcx
	movsxd	rcx, DWORD PTR i2$[rsp]
	mov	rdx, QWORD PTR pml2$[rsp]
	mov	QWORD PTR [rdx+rcx*8], rax

; 190  : 		flush_tlb((void*)page);

	mov	rcx, QWORD PTR page$2[rsp]
	call	flush_tlb

; 191  : 		x64_mfence();

	call	x64_mfence
$LN2@x86_64_map:

; 192  : 	}
; 193  : 
; 194  : 	uint64_t* pml1 = (uint64_t*)x86_64_phys_to_virt((pml2[i2] & ~(4096 - 1)));

	movsxd	rax, DWORD PTR i2$[rsp]
	mov	rcx, QWORD PTR pml2$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, -4096				; fffffffffffff000H
	mov	rcx, rax
	call	?x86_64_phys_to_virt@@YA_K_K@Z		; x86_64_phys_to_virt
	mov	QWORD PTR pml1$[rsp], rax

; 195  : 	if (pml1[i1] & PAGING_PRESENT) {

	movsxd	rax, DWORD PTR i1$[rsp]
	mov	rcx, QWORD PTR pml1$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, 1
	test	rax, rax
	je	SHORT $LN1@x86_64_map

; 196  : 		x86_64_pmmngr_free((void*)phys);

	mov	rcx, QWORD PTR phys$[rsp]
	call	?x86_64_pmmngr_free@@YAXPEAX@Z		; x86_64_pmmngr_free

; 197  : 		return false;

	xor	al, al
	jmp	SHORT $LN6@x86_64_map
$LN1@x86_64_map:

; 198  : 	}
; 199  : 
; 200  : 	pml1[i1] = phys | flags;

	mov	rax, QWORD PTR flags$[rsp]
	mov	rcx, QWORD PTR phys$[rsp]
	or	rcx, rax
	mov	rax, rcx
	movsxd	rcx, DWORD PTR i1$[rsp]
	mov	rdx, QWORD PTR pml1$[rsp]
	mov	QWORD PTR [rdx+rcx*8], rax

; 201  : 	flush_tlb((void*)virt);

	mov	rcx, QWORD PTR virt$[rsp]
	call	flush_tlb

; 202  : 	x64_mfence();

	call	x64_mfence

; 203  : 	return true;

	mov	al, 1
$LN6@x86_64_map:

; 204  : }

	add	rsp, 120				; 00000078H
	ret	0
?x86_64_map_page@@YA_N_K0E@Z ENDP			; x86_64_map_page
_TEXT	ENDS
; Function compile flags: /Odtpy
; File e:\aurora kernel\kernel\arch\x86_64\x86_64_paging.cpp
_TEXT	SEGMENT
phys_addr$ = 48
?x86_64_virt_to_phys@@YA_K_K@Z PROC			; x86_64_virt_to_phys

; 144  : uint64_t x86_64_virt_to_phys(uint64_t phys_addr) {

$LN5:
	mov	QWORD PTR [rsp+8], rcx
	sub	rsp, 40					; 00000028H

; 145  : 	if (x86_64_pmmngr_is_high_mem())

	call	?x86_64_pmmngr_is_high_mem@@YA_NXZ	; x86_64_pmmngr_is_high_mem
	movzx	eax, al
	test	eax, eax
	je	SHORT $LN2@x86_64_vir

; 146  : 		return (phys_addr - PHYSICAL_MEMORY_BASE);

	mov	rax, 140737488355328			; 0000800000000000H
	mov	rcx, QWORD PTR phys_addr$[rsp]
	add	rcx, rax
	mov	rax, rcx
	jmp	SHORT $LN3@x86_64_vir

; 147  : 	else

	jmp	SHORT $LN1@x86_64_vir
$LN2@x86_64_vir:

; 148  : 		return 0;

	xor	eax, eax
$LN1@x86_64_vir:
$LN3@x86_64_vir:

; 149  : }

	add	rsp, 40					; 00000028H
	ret	0
?x86_64_virt_to_phys@@YA_K_K@Z ENDP			; x86_64_virt_to_phys
_TEXT	ENDS
; Function compile flags: /Odtpy
; File e:\aurora kernel\kernel\arch\x86_64\x86_64_paging.cpp
_TEXT	SEGMENT
phys_addr$ = 48
?x86_64_phys_to_virt@@YA_K_K@Z PROC			; x86_64_phys_to_virt

; 133  : uint64_t x86_64_phys_to_virt(uint64_t phys_addr) {

$LN5:
	mov	QWORD PTR [rsp+8], rcx
	sub	rsp, 40					; 00000028H

; 134  : 	if (x86_64_pmmngr_is_high_mem())

	call	?x86_64_pmmngr_is_high_mem@@YA_NXZ	; x86_64_pmmngr_is_high_mem
	movzx	eax, al
	test	eax, eax
	je	SHORT $LN2@x86_64_phy

; 135  : 		return (PHYSICAL_MEMORY_BASE + phys_addr);

	mov	rax, 140737488355328			; 0000800000000000H
	mov	rcx, QWORD PTR phys_addr$[rsp]
	sub	rcx, rax
	mov	rax, rcx
	jmp	SHORT $LN3@x86_64_phy

; 136  : 	else

	jmp	SHORT $LN1@x86_64_phy
$LN2@x86_64_phy:

; 137  : 		return phys_addr;

	mov	rax, QWORD PTR phys_addr$[rsp]
$LN1@x86_64_phy:
$LN3@x86_64_phy:

; 138  : }

	add	rsp, 40					; 00000028H
	ret	0
?x86_64_phys_to_virt@@YA_K_K@Z ENDP			; x86_64_phys_to_virt
_TEXT	ENDS
; Function compile flags: /Odtpy
; File e:\aurora kernel\kernel\arch\x86_64\x86_64_paging.cpp
_TEXT	SEGMENT
i3$ = 32
i2$ = 36
i4$ = 40
flags$ = 48
page$1 = 56
pml3$ = 64
i1$ = 72
page$2 = 80
page$3 = 88
pml2$ = 96
pml4i$ = 104
pml1$ = 112
physical_address$ = 144
virtual_address$ = 152
attrib$ = 160
?early_map_page@@YA_N_K0E@Z PROC			; early_map_page

; 46   : bool early_map_page(uint64_t physical_address, uint64_t virtual_address, uint8_t attrib){

$LN6:
	mov	BYTE PTR [rsp+24], r8b
	mov	QWORD PTR [rsp+16], rdx
	mov	QWORD PTR [rsp+8], rcx
	sub	rsp, 136				; 00000088H

; 47   : 	size_t flags = PAGING_WRITABLE | PAGING_PRESENT | attrib;

	movzx	eax, BYTE PTR attrib$[rsp]
	or	eax, 3
	cdqe
	mov	QWORD PTR flags$[rsp], rax

; 48   : 
; 49   : 	const long i4 = (virtual_address >> 39) & 0x1FF;

	mov	rax, QWORD PTR virtual_address$[rsp]
	shr	rax, 39					; 00000027H
	and	rax, 511				; 000001ffH
	mov	DWORD PTR i4$[rsp], eax

; 50   : 	const long i3 = (virtual_address >> 30) & 0x1FF;

	mov	rax, QWORD PTR virtual_address$[rsp]
	shr	rax, 30
	and	rax, 511				; 000001ffH
	mov	DWORD PTR i3$[rsp], eax

; 51   : 	const long i2 = (virtual_address >> 21) & 0x1FF;

	mov	rax, QWORD PTR virtual_address$[rsp]
	shr	rax, 21
	and	rax, 511				; 000001ffH
	mov	DWORD PTR i2$[rsp], eax

; 52   : 	const long i1 = (virtual_address >> 12) & 0x1FF;

	mov	rax, QWORD PTR virtual_address$[rsp]
	shr	rax, 12
	and	rax, 511				; 000001ffH
	mov	DWORD PTR i1$[rsp], eax

; 53   : 
; 54   : 	uint64_t *pml4i = (uint64_t*)x64_read_cr3();

	call	x64_read_cr3
	mov	QWORD PTR pml4i$[rsp], rax

; 55   : 	if (!(pml4i[i4] & PAGING_PRESENT)){

	movsxd	rax, DWORD PTR i4$[rsp]
	mov	rcx, QWORD PTR pml4i$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, 1
	test	rax, rax
	jne	SHORT $LN3@early_map_

; 56   : 
; 57   : 		const uint64_t page = (uint64_t)x86_64_pmmngr_alloc();

	call	?x86_64_pmmngr_alloc@@YAPEAXXZ		; x86_64_pmmngr_alloc
	mov	QWORD PTR page$1[rsp], rax

; 58   : 		pml4i[i4] = page | flags;

	mov	rax, QWORD PTR flags$[rsp]
	mov	rcx, QWORD PTR page$1[rsp]
	or	rcx, rax
	mov	rax, rcx
	movsxd	rcx, DWORD PTR i4$[rsp]
	mov	rdx, QWORD PTR pml4i$[rsp]
	mov	QWORD PTR [rdx+rcx*8], rax

; 59   : 		memset((void*)page, 0, 4096);

	mov	r8d, 4096				; 00001000H
	xor	edx, edx
	mov	rcx, QWORD PTR page$1[rsp]
	call	?memset@@YAXPEAXEI@Z			; memset

; 60   : 		flush_tlb((void*)page);

	mov	rcx, QWORD PTR page$1[rsp]
	call	flush_tlb

; 61   : 		x64_mfence();

	call	x64_mfence
$LN3@early_map_:

; 62   : 	}
; 63   : 	uint64_t* pml3 = (uint64_t*)(pml4i[i4] & ~(4096 - 1));

	movsxd	rax, DWORD PTR i4$[rsp]
	mov	rcx, QWORD PTR pml4i$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, -4096				; fffffffffffff000H
	mov	QWORD PTR pml3$[rsp], rax

; 64   : 
; 65   : 	if (!(pml3[i3] & PAGING_PRESENT))

	movsxd	rax, DWORD PTR i3$[rsp]
	mov	rcx, QWORD PTR pml3$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, 1
	test	rax, rax
	jne	SHORT $LN2@early_map_

; 66   : 	{
; 67   : 		const uint64_t page = (uint64_t)x86_64_pmmngr_alloc();

	call	?x86_64_pmmngr_alloc@@YAPEAXXZ		; x86_64_pmmngr_alloc
	mov	QWORD PTR page$3[rsp], rax

; 68   : 		pml3[i3] = page | flags;

	mov	rax, QWORD PTR flags$[rsp]
	mov	rcx, QWORD PTR page$3[rsp]
	or	rcx, rax
	mov	rax, rcx
	movsxd	rcx, DWORD PTR i3$[rsp]
	mov	rdx, QWORD PTR pml3$[rsp]
	mov	QWORD PTR [rdx+rcx*8], rax

; 69   : 		memset((void*)page, 0, 4096);

	mov	r8d, 4096				; 00001000H
	xor	edx, edx
	mov	rcx, QWORD PTR page$3[rsp]
	call	?memset@@YAXPEAXEI@Z			; memset

; 70   : 		flush_tlb((void*)page);

	mov	rcx, QWORD PTR page$3[rsp]
	call	flush_tlb

; 71   : 		x64_mfence();

	call	x64_mfence
$LN2@early_map_:

; 72   : 	}
; 73   : 
; 74   : 	uint64_t* pml2 = (uint64_t*)(pml3[i3] & ~(4096 - 1));

	movsxd	rax, DWORD PTR i3$[rsp]
	mov	rcx, QWORD PTR pml3$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, -4096				; fffffffffffff000H
	mov	QWORD PTR pml2$[rsp], rax

; 75   : 
; 76   : 	if (!(pml2[i2] & PAGING_PRESENT)){

	movsxd	rax, DWORD PTR i2$[rsp]
	mov	rcx, QWORD PTR pml2$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, 1
	test	rax, rax
	jne	SHORT $LN1@early_map_

; 77   : 		const uint64_t page = (uint64_t)x86_64_pmmngr_alloc();

	call	?x86_64_pmmngr_alloc@@YAPEAXXZ		; x86_64_pmmngr_alloc
	mov	QWORD PTR page$2[rsp], rax

; 78   : 		pml2[i2] = page | flags;

	mov	rax, QWORD PTR flags$[rsp]
	mov	rcx, QWORD PTR page$2[rsp]
	or	rcx, rax
	mov	rax, rcx
	movsxd	rcx, DWORD PTR i2$[rsp]
	mov	rdx, QWORD PTR pml2$[rsp]
	mov	QWORD PTR [rdx+rcx*8], rax

; 79   : 		memset((void*)page, 0, 4096);

	mov	r8d, 4096				; 00001000H
	xor	edx, edx
	mov	rcx, QWORD PTR page$2[rsp]
	call	?memset@@YAXPEAXEI@Z			; memset

; 80   : 		flush_tlb((void*)page);

	mov	rcx, QWORD PTR page$2[rsp]
	call	flush_tlb

; 81   : 		x64_mfence();

	call	x64_mfence
$LN1@early_map_:

; 82   : 	}
; 83   : 
; 84   : 	uint64_t* pml1 = (uint64_t*)(pml2[i2] & ~(4096 - 1));

	movsxd	rax, DWORD PTR i2$[rsp]
	mov	rcx, QWORD PTR pml2$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, -4096				; fffffffffffff000H
	mov	QWORD PTR pml1$[rsp], rax

; 85   : 
; 86   : 	pml1[i1] = physical_address | flags;

	mov	rax, QWORD PTR flags$[rsp]
	mov	rcx, QWORD PTR physical_address$[rsp]
	or	rcx, rax
	mov	rax, rcx
	movsxd	rcx, DWORD PTR i1$[rsp]
	mov	rdx, QWORD PTR pml1$[rsp]
	mov	QWORD PTR [rdx+rcx*8], rax

; 87   : 	flush_tlb((void*)virtual_address);

	mov	rcx, QWORD PTR virtual_address$[rsp]
	call	flush_tlb

; 88   : 	x64_mfence();

	call	x64_mfence

; 89   : 	return true;

	mov	al, 1

; 90   : }

	add	rsp, 136				; 00000088H
	ret	0
?early_map_page@@YA_N_K0E@Z ENDP			; early_map_page
_TEXT	ENDS
; Function compile flags: /Odtpy
; File e:\aurora kernel\kernel\arch\x86_64\x86_64_paging.cpp
_TEXT	SEGMENT
i$1 = 32
i$2 = 36
i$3 = 40
new_cr3$ = 48
old_cr3$ = 56
?x86_64_paging_init@@YAHXZ PROC				; x86_64_paging_init

; 96   : int x86_64_paging_init() {

$LN15:
	sub	rsp, 72					; 00000048H

; 97   : 
; 98   : 	uint64_t* old_cr3 = (uint64_t*)x64_read_cr3();

	call	x64_read_cr3
	mov	QWORD PTR old_cr3$[rsp], rax

; 99   : 	uint64_t* new_cr3 = (uint64_t*)x86_64_pmmngr_alloc();

	call	?x86_64_pmmngr_alloc@@YAPEAXXZ		; x86_64_pmmngr_alloc
	mov	QWORD PTR new_cr3$[rsp], rax

; 100  : 	memset(new_cr3, 0, 4096);

	mov	r8d, 4096				; 00001000H
	xor	edx, edx
	mov	rcx, QWORD PTR new_cr3$[rsp]
	call	?memset@@YAXPEAXEI@Z			; memset

; 101  : 
; 102  : 	/* copy entire address space to new address space */
; 103  : 	for (int i = 0; i < 512; i++) {

	mov	DWORD PTR i$1[rsp], 0
	jmp	SHORT $LN12@x86_64_pag
$LN11@x86_64_pag:
	mov	eax, DWORD PTR i$1[rsp]
	inc	eax
	mov	DWORD PTR i$1[rsp], eax
$LN12@x86_64_pag:
	cmp	DWORD PTR i$1[rsp], 512			; 00000200H
	jge	SHORT $LN10@x86_64_pag

; 104  : 		if (i == 511)

	cmp	DWORD PTR i$1[rsp], 511			; 000001ffH
	jne	SHORT $LN9@x86_64_pag

; 105  : 			continue;

	jmp	SHORT $LN11@x86_64_pag
$LN9@x86_64_pag:

; 106  : 
; 107  : 		if (old_cr3[i] & 0x1)

	movsxd	rax, DWORD PTR i$1[rsp]
	mov	rcx, QWORD PTR old_cr3$[rsp]
	mov	rax, QWORD PTR [rcx+rax*8]
	and	rax, 1
	test	rax, rax
	je	SHORT $LN8@x86_64_pag

; 108  : 			new_cr3[i] = old_cr3[i];

	movsxd	rax, DWORD PTR i$1[rsp]
	movsxd	rcx, DWORD PTR i$1[rsp]
	mov	rdx, QWORD PTR new_cr3$[rsp]
	mov	r8, QWORD PTR old_cr3$[rsp]
	mov	rax, QWORD PTR [r8+rax*8]
	mov	QWORD PTR [rdx+rcx*8], rax

; 109  : 		else

	jmp	SHORT $LN7@x86_64_pag
$LN8@x86_64_pag:

; 110  : 			new_cr3[i] = 0;

	movsxd	rax, DWORD PTR i$1[rsp]
	mov	rcx, QWORD PTR new_cr3$[rsp]
	mov	QWORD PTR [rcx+rax*8], 0
$LN7@x86_64_pag:

; 111  : 	}

	jmp	SHORT $LN11@x86_64_pag
$LN10@x86_64_pag:

; 112  : 
; 113  : 	x64_write_cr3((size_t)new_cr3);

	mov	rcx, QWORD PTR new_cr3$[rsp]
	call	x64_write_cr3

; 114  : 
; 115  : 	/* map entire physical memory to PHYSICAL_MEMORY_BASE */
; 116  : 	for (uint64_t i = 0; i < x86_64_pmmngr_get_total_mem() / 4096; i++)

	mov	QWORD PTR i$3[rsp], 0
	jmp	SHORT $LN6@x86_64_pag
$LN5@x86_64_pag:
	mov	rax, QWORD PTR i$3[rsp]
	inc	rax
	mov	QWORD PTR i$3[rsp], rax
$LN6@x86_64_pag:
	call	?x86_64_pmmngr_get_total_mem@@YA_KXZ	; x86_64_pmmngr_get_total_mem
	xor	edx, edx
	mov	ecx, 4096				; 00001000H
	div	rcx
	cmp	QWORD PTR i$3[rsp], rax
	jae	SHORT $LN4@x86_64_pag

; 117  : 		early_map_page(0x0 + i * 4096, PHYSICAL_MEMORY_BASE + i * 4096, 0);

	imul	rax, QWORD PTR i$3[rsp], 4096		; 00001000H
	mov	rcx, 140737488355328			; 0000800000000000H
	sub	rax, rcx
	imul	rcx, QWORD PTR i$3[rsp], 4096		; 00001000H
	xor	r8d, r8d
	mov	rdx, rax
	call	?early_map_page@@YA_N_K0E@Z		; early_map_page
	jmp	SHORT $LN5@x86_64_pag
$LN4@x86_64_pag:

; 118  : 
; 119  : 	/* clear up the lower half*/
; 120  : 	for (int i = 0; i < 256; i++)

	mov	DWORD PTR i$2[rsp], 0
	jmp	SHORT $LN3@x86_64_pag
$LN2@x86_64_pag:
	mov	eax, DWORD PTR i$2[rsp]
	inc	eax
	mov	DWORD PTR i$2[rsp], eax
$LN3@x86_64_pag:
	cmp	DWORD PTR i$2[rsp], 256			; 00000100H
	jge	SHORT $LN1@x86_64_pag

; 121  : 		new_cr3[i] = 0;

	movsxd	rax, DWORD PTR i$2[rsp]
	mov	rcx, QWORD PTR new_cr3$[rsp]
	mov	QWORD PTR [rcx+rax*8], 0
	jmp	SHORT $LN2@x86_64_pag
$LN1@x86_64_pag:

; 122  : 
; 123  : 	/* from here we are fully boot free*/
; 124  : 	x86_64_pmmngr_set_high(true);

	mov	cl, 1
	call	?x86_64_pmmngr_set_high@@YAX_N@Z	; x86_64_pmmngr_set_high

; 125  : 	x86_64_pmmngr_high_mem_bitmap();

	call	?x86_64_pmmngr_high_mem_bitmap@@YAXXZ	; x86_64_pmmngr_high_mem_bitmap

; 126  : 	return 0;

	xor	eax, eax

; 127  : }

	add	rsp, 72					; 00000048H
	ret	0
?x86_64_paging_init@@YAHXZ ENDP				; x86_64_paging_init
_TEXT	ENDS
END
